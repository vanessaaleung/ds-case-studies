{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Natural Language Processing With spaCy.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zIRiJWgiJpt-",
        "cRmPmIBYKSdP",
        "r3nU43C2Kqp0",
        "TT1SgXdnK-A7",
        "gQSkgLNiLaLx",
        "pLVZmDAXL61m"
      ],
      "authorship_tag": "ABX9TyPlYnWPGzUJxV4MJlTlN8sH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanessaaleung/natural-language-processing-with-spaCy/blob/master/Natural_Language_Processing_With_spaCy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZgaiDo0RsZS",
        "colab_type": "text"
      },
      "source": [
        "### **Natural Language Processing With spaCy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VMJLnYVIjI0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtrD3g_II1Nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "introduction_text = ('This tutorial is about Natural Language Processing in Spacy.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqhpJbsgJLRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a processed Doc object - a container for accessing linguistic annotations\n",
        "introduction_doc = nlp(introduction_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIRiJWgiJpt-",
        "colab_type": "text"
      },
      "source": [
        "#### **Sentence Detection**\n",
        "Sentence Detection is the process of locating the start and end of sentences in a given text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6LRiI8yJWCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "complete_text = ('Gus Proto is a Python developer currently'\n",
        "...     'working for a London-based Fintech company. He is'\n",
        "...     ' interested in learning Natural Language Processing.'\n",
        "...     ' There is a developer conference happening on 21 July'\n",
        "...     ' 2019 in London. It is titled \"Applications of Natural'\n",
        "...     ' Language Processing\". There is a helpline number '\n",
        "...     ' available at +1-1234567891. Gus is helping organize it.'\n",
        "...     ' He keeps organizing local Python meetups and several'\n",
        "...     ' internal talks at his workplace. Gus is also presenting'\n",
        "...     ' a talk. The talk will introduce the reader about \"Use'\n",
        "...     ' cases of Natural Language Processing in Fintech\".'\n",
        "...     ' Apart from his work, he is very passionate about music.'\n",
        "...     ' Gus is learning to play the Piano. He has enrolled '\n",
        "...     ' himself in the weekend batch of Great Piano Academy.'\n",
        "...     ' Great Piano Academy is situated in Mayfair or the City'\n",
        "...     ' of London and has world-class piano instructors.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnZVn7KCJ1Bu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f914321-1a1f-4504-f72a-695e28ba646b"
      },
      "source": [
        "complete_doc = nlp(complete_text)\n",
        "sentences = list(complete_doc.sents)\n",
        "len(sentences)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x4GDnK8J4Kn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "9e642358-d63e-48c4-cbb9-ff8bb5492130"
      },
      "source": [
        "for sentence in sentences:\n",
        "  print (sentence)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gus Proto is a Python developer currentlyworking for a London-based Fintech company.\n",
            "He is interested in learning Natural Language Processing.\n",
            "There is a developer conference happening on 21 July 2019 in London.\n",
            "It is titled \"Applications of Natural Language Processing\".\n",
            "There is a helpline number  available at +1-1234567891.\n",
            "Gus is helping organize it.\n",
            "He keeps organizing local Python meetups and several internal talks at his workplace.\n",
            "Gus is also presenting a talk.\n",
            "The talk will introduce the reader about \"Use cases of Natural Language Processing in Fintech\".\n",
            "Apart from his work, he is very passionate about music.\n",
            "Gus is learning to play the Piano.\n",
            "He has enrolled  himself in the weekend batch of Great Piano Academy.\n",
            "Great Piano Academy is situated in Mayfair or the City of London and has world-class piano instructors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRmPmIBYKSdP",
        "colab_type": "text"
      },
      "source": [
        "#### **Tokenization**\n",
        "Identify the basic units in the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSRKgzmKJ5nu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2539a0dc-c296-4e52-a398-5dd72e561092"
      },
      "source": [
        "print([token for token in complete_doc])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Gus, Proto, is, a, Python, developer, currentlyworking, for, a, London, -, based, Fintech, company, ., He, is, interested, in, learning, Natural, Language, Processing, ., There, is, a, developer, conference, happening, on, 21, July, 2019, in, London, ., It, is, titled, \", Applications, of, Natural, Language, Processing, \", ., There, is, a, helpline, number,  , available, at, +1, -, 1234567891, ., Gus, is, helping, organize, it, ., He, keeps, organizing, local, Python, meetups, and, several, internal, talks, at, his, workplace, ., Gus, is, also, presenting, a, talk, ., The, talk, will, introduce, the, reader, about, \", Use, cases, of, Natural, Language, Processing, in, Fintech, \", ., Apart, from, his, work, ,, he, is, very, passionate, about, music, ., Gus, is, learning, to, play, the, Piano, ., He, has, enrolled,  , himself, in, the, weekend, batch, of, Great, Piano, Academy, ., Great, Piano, Academy, is, situated, in, Mayfair, or, the, City, of, London, and, has, world, -, class, piano, instructors, .]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3nU43C2Kqp0",
        "colab_type": "text"
      },
      "source": [
        "#### **Stop Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0mQ3DqgKecz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91186d4b-ad22-4a30-b810-f381e5da22c7"
      },
      "source": [
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "len(spacy_stopwords)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "326"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL5Rh_pWK5H0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "84a35cae-da33-4502-8b0d-a7fa0d195a9e"
      },
      "source": [
        "complete_no_stopword_doc = [token for token in complete_doc if not token.is_stop]\n",
        "print(complete_no_stopword_doc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Gus, Proto, Python, developer, currentlyworking, London, -, based, Fintech, company, ., interested, learning, Natural, Language, Processing, ., developer, conference, happening, 21, July, 2019, London, ., titled, \", Applications, Natural, Language, Processing, \", ., helpline, number,  , available, +1, -, 1234567891, ., Gus, helping, organize, ., keeps, organizing, local, Python, meetups, internal, talks, workplace, ., Gus, presenting, talk, ., talk, introduce, reader, \", Use, cases, Natural, Language, Processing, Fintech, \", ., Apart, work, ,, passionate, music, ., Gus, learning, play, Piano, ., enrolled,  , weekend, batch, Great, Piano, Academy, ., Great, Piano, Academy, situated, Mayfair, City, London, world, -, class, piano, instructors, .]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT1SgXdnK-A7",
        "colab_type": "text"
      },
      "source": [
        "#### **Lemmatization**\n",
        "Reducing inflected forms of a word. The reduced form or root word is called a lemma."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HToLxHG2K880",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "49d4bbfc-e592-4b79-aa15-a192e065e186"
      },
      "source": [
        "print([token.lemma_ for token in complete_no_stopword_doc])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Gus', 'Proto', 'Python', 'developer', 'currentlyworke', 'London', '-', 'base', 'Fintech', 'company', '.', 'interested', 'learn', 'Natural', 'Language', 'Processing', '.', 'developer', 'conference', 'happen', '21', 'July', '2019', 'London', '.', 'title', '\"', 'Applications', 'Natural', 'Language', 'Processing', '\"', '.', 'helpline', 'number', ' ', 'available', '+1', '-', '1234567891', '.', 'Gus', 'help', 'organize', '.', 'keep', 'organize', 'local', 'Python', 'meetup', 'internal', 'talk', 'workplace', '.', 'Gus', 'present', 'talk', '.', 'talk', 'introduce', 'reader', '\"', 'use', 'case', 'Natural', 'Language', 'Processing', 'Fintech', '\"', '.', 'apart', 'work', ',', 'passionate', 'music', '.', 'Gus', 'learn', 'play', 'Piano', '.', 'enrol', ' ', 'weekend', 'batch', 'Great', 'Piano', 'Academy', '.', 'Great', 'Piano', 'Academy', 'situate', 'Mayfair', 'City', 'London', 'world', '-', 'class', 'piano', 'instructor', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQSkgLNiLaLx",
        "colab_type": "text"
      },
      "source": [
        "#### **Word Frequency**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vtsZ5doLWM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f823eb49-314d-43cd-9401-58e32480a852"
      },
      "source": [
        "from collections import Counter\n",
        "words = [token.text for token in complete_doc if not token.is_stop and not token.is_punct]\n",
        "word_freq = Counter(words)\n",
        "word_freq.most_common(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Gus', 4), ('London', 3), ('Natural', 3), ('Language', 3), ('Processing', 3)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLVZmDAXL61m",
        "colab_type": "text"
      },
      "source": [
        "#### **Part of Speech Tagging**\n",
        "There are eight [parts of speech](https://spacy.io/api/annotation#pos-tagging):\n",
        "\n",
        "- Noun ```NNP, PROPN```\n",
        "- Pronoun ```PRP, PRON```\n",
        "- Adjective ``JJ, JJR, JJS, ADJ``\n",
        "- Verb ```VB, VBD, VBG, VBP, VBZ, VERB```\n",
        "- Adverb ```RB, RBR, TBS, RP, ADV```\n",
        "- Preposition ```IN, ADP```\n",
        "- Conjunction ```CC, CCONJ```\n",
        "- Interjection ```UH, INTJ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJXi3s4aLzvI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d9325cb5-89e7-45d7-c5b9-cae458685237"
      },
      "source": [
        "for token in complete_no_stopword_doc[:5]:\n",
        "  print(token, \n",
        "        token.tag_, \n",
        "        token.pos_, \n",
        "        spacy.explain(token.tag_))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gus NNP PROPN noun, proper singular\n",
            "Proto NNP PROPN noun, proper singular\n",
            "Python NNP PROPN noun, proper singular\n",
            "developer NN NOUN noun, singular or mass\n",
            "currentlyworking VBG VERB verb, gerund or present participle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oFh4dNaOxTa",
        "colab_type": "text"
      },
      "source": [
        "#### **Rule-Based Matching**\n",
        "Identify and extract tokens and phrases according to patterns (such as lowercase) and grammatical features (such as part of speech)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixwmEMkPOhiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "acd623e4-2e48-4ccd-8219-ee1bab96ac24"
      },
      "source": [
        "from spacy.matcher import Matcher\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "def extract_full_name(nlp_doc):\n",
        "  pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "  matcher.add('FULL_NAME', None, pattern)  # matcher.add(ID key, callback, list of dicts of patterns)\n",
        "  matches = matcher(nlp_doc)   # Find all token sequences matching the supplied patterns on the Doc\n",
        "  for match_id, start, end in matches:\n",
        "    span = nlp_doc[start:end]\n",
        "    print(span.text)\n",
        "\n",
        "extract_full_name(complete_doc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gus Proto\n",
            "Natural Language\n",
            "Language Processing\n",
            "Natural Language\n",
            "Language Processing\n",
            "Natural Language\n",
            "Language Processing\n",
            "Great Piano\n",
            "Piano Academy\n",
            "Great Piano\n",
            "Piano Academy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-606fp7Q_48",
        "colab_type": "text"
      },
      "source": [
        "- ```ORTH``` gives the exact text of the token\n",
        "- ```SHAPE``` transforms the token string to show orthographic features\n",
        "- ```OP``` defines operators. The pattern is optional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fECxxi1JPcvb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93f1d282-2f73-4e51-96b0-ac088ef6e36d"
      },
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "conference_org_text = ('There is a developer conference'\n",
        "     'happening on 21 July 2019 in London. It is titled'\n",
        "     ' \"Applications of Natural Language Processing\".'\n",
        "     ' There is a helpline number available'\n",
        "     ' at (123) 456-789')\n",
        "\n",
        "def extract_phone_number(nlp_doc):\n",
        "     pattern = [{'ORTH': '('}, {'SHAPE': 'ddd'},\n",
        "                {'ORTH': ')'}, {'SHAPE': 'ddd'},\n",
        "                {'ORTH': '-', 'OP': '?'},\n",
        "                {'SHAPE': 'ddd'}]\n",
        "     matcher.add('PHONE_NUMBER', None, pattern)\n",
        "     matches = matcher(nlp_doc)\n",
        "     for match_id, start, end in matches:\n",
        "         span = nlp_doc[start:end]\n",
        "         return span.text\n",
        "\n",
        "conference_org_doc = nlp(conference_org_text)\n",
        "extract_phone_number(conference_org_doc)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'(123) 456-789'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0urNKdUR2Fv",
        "colab_type": "text"
      },
      "source": [
        "#### **Dependency Parsing**\n",
        "Defines the dependency relationship between headwords and their dependents. The verb is usually the head of the sentence.\n",
        "\n",
        "\n",
        "- ```nsubj``` is the subject of the word. Its headword is a verb.\n",
        "- ```aux``` is an auxiliary word. Its headword is a verb.\n",
        "- ```dobj``` is the direct object of the verb. Its headword is a verb.\n",
        "- ```acomp```: adjectival complement. Its headword is a verb.\n",
        "- ```pcomp```: prepositional complement. Its headword is a preposition.\n",
        "- ```prep```\n",
        "- ```ROOT```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvDB0ihNSGm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3f444af8-cdfc-4219-8f3d-85821645fa0d"
      },
      "source": [
        "about_interest_text = ('He is interested in learning Natural Language Processing.')\n",
        "about_interest_doc = nlp(about_interest_text)\n",
        "for token in about_interest_doc[:5]:\n",
        "  print(token.text, token.head.text, token.dep_)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He is nsubj\n",
            "is is ROOT\n",
            "interested is acomp\n",
            "in interested prep\n",
            "learning in pcomp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWD7qaUeMlwA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4c85c0ea-7a45-423f-a8b8-3ff947dc7fce"
      },
      "source": [
        "from spacy import displacy\n",
        "displacy.render(about_interest_doc, style='dep', jupyter=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"6129458aa63349c59f6199693b9c720c-0\" class=\"displacy\" width=\"1450\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">He</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">interested</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Natural</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Language</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">Processing.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6129458aa63349c59f6199693b9c720c-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6129458aa63349c59f6199693b9c720c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6129458aa63349c59f6199693b9c720c-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6129458aa63349c59f6199693b9c720c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6129458aa63349c59f6199693b9c720c-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6129458aa63349c59f6199693b9c720c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6129458aa63349c59f6199693b9c720c-0-3\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6129458aa63349c59f6199693b9c720c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M745.0,179.0 L753.0,167.0 737.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6129458aa63349c59f6199693b9c720c-0-4\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6129458aa63349c59f6199693b9c720c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M945,179.0 L937,167.0 953,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6129458aa63349c59f6199693b9c720c-0-5\" stroke-width=\"2px\" d=\"M1120,177.0 C1120,89.5 1270.0,89.5 1270.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6129458aa63349c59f6199693b9c720c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1120,179.0 L1112,167.0 1128,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-6129458aa63349c59f6199693b9c720c-0-6\" stroke-width=\"2px\" d=\"M770,177.0 C770,2.0 1275.0,2.0 1275.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-6129458aa63349c59f6199693b9c720c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1275.0,179.0 L1283.0,167.0 1267.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OjLQwBCT64p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "853b7cb9-5dac-4068-fde0-e335e3799c8f"
      },
      "source": [
        "# extract the children of 'is'\n",
        "print([token.text for token in about_interest_doc[1].children])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['He', 'interested', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEGKIxvbUEws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "134dd884-ea13-419d-ad0e-302efae223b9"
      },
      "source": [
        "# extract the previous neighboring node of 'is'\n",
        "print(about_interest_doc[1].nbor(-1))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40Fp_ja4UJme",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7b7f968c-2960-4e20-c953-292b81eff48a"
      },
      "source": [
        "# extract the next neighboring node of 'is'\n",
        "print(about_interest_doc[1].nbor())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "interested\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtLk3FCPUOyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f7c87739-d7ed-4231-d3b6-61fcdd62a2b0"
      },
      "source": [
        "# extract all left/right tokens of 'is'\n",
        "print([token.text for token in about_interest_doc[1].lefts])\n",
        "print([token.text for token in about_interest_doc[1].rights])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['He']\n",
            "['interested', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2R4Du3QUzaL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "91e7bf31-4d5d-456b-958e-6a2c7b99d7ff"
      },
      "source": [
        "print(list(about_interest_doc[1].subtree))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[He, is, interested, in, learning, Natural, Language, Processing, .]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA8zuRJQT3p_",
        "colab_type": "text"
      },
      "source": [
        "#### **Shallow Parsing/Chuncking**\n",
        "Groups adjacent tokens into phrases on the basis of their POS tags. There are some standard well-known chunks such as noun phrases, verb phrases, and prepositional phrases.\n",
        "\n",
        "- Noun Phrase: has a noun as its head. Help infer what is being talked about in the sentence.\n",
        "- Verb Phrase: has at least one  verb. Help understand the actions of the nouns. Requires `textacy` package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIPHY1xWVavM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4bb28143-21bb-4a7f-9df8-ea97261870b1"
      },
      "source": [
        "# noun phrase detection\n",
        "for chunk in about_interest_doc.noun_chunks:\n",
        "  print(chunk)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "He\n",
            "Natural Language Processing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BMw3tVtVfC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "84a2d3ba-a675-4653-fd5f-34fa7aafe938"
      },
      "source": [
        "!pip3 install textacy --progress-bar off\n",
        "import textacy"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textacy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/fe/0b57ac1a202de9819e71e8373980d586e824f515ad2f4266e4e98627f8b8/textacy-0.10.0-py3-none-any.whl (206kB)\n",
            "\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.18.4)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.6/dist-packages (from textacy) (4.41.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.22.2.post1)\n",
            "Collecting jellyfish>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/09/927ae35fc5a9f70abb6cc2c27ee88fc48549f7bc4786c1d4b177c22e997d/jellyfish-0.8.2-cp36-cp36m-manylinux2014_x86_64.whl (93kB)\n",
            "\n",
            "\u001b[?25hCollecting pyphen>=0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/82/08a3629dce8d1f3d91db843bb36d4d7db6b6269d5067259613a0d5c8a9db/Pyphen-0.9.5-py2.py3-none-any.whl (3.0MB)\n",
            "\n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.2.4)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.4)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (2.23.0)\n",
            "Requirement already satisfied: cachetools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from textacy) (3.1.1)\n",
            "Collecting cytoolz>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/b1/7f16703fe4a497879b1b457adf1e472fad2d4f030477698b16d2febf38bb/cytoolz-0.10.1.tar.gz (475kB)\n",
            "\n",
            "\u001b[?25hRequirement already satisfied: pyemd>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.5.1)\n",
            "Requirement already satisfied: srsly>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from textacy) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.6/dist-packages (from textacy) (0.15.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (0.6.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (46.3.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (2.0.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->textacy) (0.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->textacy) (4.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->textacy) (2.9)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz>=0.8.0->textacy) (0.10.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->textacy) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->textacy) (3.1.0)\n",
            "Building wheels for collected packages: cytoolz\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cytoolz: filename=cytoolz-0.10.1-cp36-cp36m-linux_x86_64.whl size=1233723 sha256=089c9b273c068596263081cf421e841394e671cc7ed5abee7686f01ab7e28e02\n",
            "  Stored in directory: /root/.cache/pip/wheels/64/2a/18/d962b614e055577e7d9a3e4813e0742f822ca9c8800cc3783a\n",
            "Successfully built cytoolz\n",
            "Installing collected packages: jellyfish, pyphen, cytoolz, textacy\n",
            "Successfully installed cytoolz-0.10.1 jellyfish-0.8.2 pyphen-0.9.5 textacy-0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBtd-J3cV1EN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2f796672-da36-4ec7-fe75-5cba2204b2bc"
      },
      "source": [
        "# verb phrase detection\n",
        "about_talk_text = ('The talk will introduce reader about Use'\n",
        "                    ' cases of Natural Language Processing in'\n",
        "                    ' Fintech')\n",
        "pattern = r'(<VERB>?<ADV>*<VERB>+)'\n",
        "about_interest_doc = textacy.make_spacy_doc(about_interest_text,\n",
        "                      lang='en_core_web_sm')\n",
        "verb_phrases = textacy.extract.pos_regex_matches(about_interest_doc, pattern)\n",
        "for chunk in verb_phrases:\n",
        "  print(chunk.text)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/textacy/extract.py:332: DeprecationWarning: `pos_regex_matches()` has been deprecated! for similar but more powerful and performant functionality, use `textacy.extract.matches()` instead.\n",
            "  action=\"once\",\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqm9P5XMXEOq",
        "colab_type": "text"
      },
      "source": [
        "#### **Named Entity Recognition (NER)**\n",
        "Locating named entities in text and classifying them into pre-definfed categories: person names, organizations, locations, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOApzmvwWM9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "2802eba5-c058-4b70-ac36-3c35ba44abf6"
      },
      "source": [
        "piano_class_text = ('Great Piano Academy is situated'\n",
        "...     ' in Mayfair or the City of London and has'\n",
        "...     ' world-class piano instructors.')\n",
        "piano_class_doc = nlp(piano_class_text)\n",
        "for ent in piano_class_doc.ents:\n",
        "  print(ent.text, ent.label_, spacy.explain(ent.label_))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Great Piano Academy ORG Companies, agencies, institutions, etc.\n",
            "Mayfair GPE Countries, cities, states\n",
            "the City of London GPE Countries, cities, states\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coAfwcK3XZuf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ad0f03c5-5d53-41d4-f2bc-9848b6a6fbfc"
      },
      "source": [
        "displacy.render(piano_class_doc, style='ent', jupyter=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Great Piano Academy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is situated in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mayfair\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " or \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the City of London\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and has world-class piano instructors.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MFuOrrFXzzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61eb5942-cef0-4a6c-e01f-9853921bec78"
      },
      "source": [
        "# redact people’s names from a text\n",
        "survey_text = ('Out of 5 people surveyed, James Robert,'\n",
        "                ' Julie Fuller and Benjamin Brooks like'\n",
        "                ' apples. Kelly Cox and Matthew Evans'\n",
        "                ' like oranges.')\n",
        "\n",
        "def replace_person_names(token):\n",
        "     if token.ent_iob != 0 and token.ent_type_ == 'PERSON':\n",
        "         return '[REDACTED] '\n",
        "     return token.string\n",
        "\n",
        "def redact_names(nlp_doc):\n",
        "     for ent in nlp_doc.ents:\n",
        "         ent.merge()\n",
        "     tokens = map(replace_person_names, nlp_doc)\n",
        "     return ''.join(tokens)\n",
        "\n",
        "survey_doc = nlp(survey_text)\n",
        "redact_names(survey_doc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Out of 5 people surveyed, [REDACTED] , [REDACTED] and [REDACTED] like apples. [REDACTED] and [REDACTED] like oranges.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdCRfTNgSeI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}